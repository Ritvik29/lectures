---
title: 'STAT636: Unsupervised Imputation'
subtitle: How to deal with missing values
output:
  html_document: default
---
# Loading packages
```{r} 
if(!require(tidyverse)){install.packages('tidyverse');require(tidyverse)}
```


# Summary
Missing data is incredibly common in practice.  Hence, we need a variety of practical ways to deal with missingness so we can choose an appropriate method for a given situation.

Note that missingness generally just references the features.  If the
supervisor is missing, then that observation is in need of prediction not imputation.

# Running example: Simulation
```{r}
set.seed(1)
X_c         = matrix(rnorm(12),nrow=6) %*% matrix(c(1,.75,.75,1),nrow=2)
X           = X_c
X[c(1,2),1] = NA

Y           = rnorm(nrow(X))

X_c
X
```

# Listwise deletion
This is the default of most statistical computing packages/functions

All it means is we ignore observations with missing data

For example, if we wanted to do a regression:
```{r}
(summary(lm(Y~X)))
```
As 1/3 of the values in the first feature is missing, we can instead remove that feature and just regress on the second:
```{r}
(summary(lm(Y~X[,2])))
```

This works fine as long as 

* You have a lot of data
* There isn't much missing
* The data are ``Missing Completely at Random'' (MCAR)


Referring to our running example, the missing values in X are created via an MCAR mechanism

Let's look at what listwise deletion looks like.  See [here]("https://r4ds.had.co.nz/data-visualisation.html") for a tutorial on ggplot.
```{r}
ggplot(data = data.frame('x1' = X_c[,1],'x1NA' = X[,1], 'Y' = Y), aes(x1,Y)) + 
  geom_point(mapping = aes(color = is.na(X[,1]))) + 
  geom_smooth(method='lm', color='blue', se = FALSE) + 
  geom_smooth(mapping = aes(x1NA,Y), method='lm',na.rm = TRUE, color='red', se = FALSE)
```


# Mean/median/mode imputation
The simplest (conceptually and computationally) imputation method
```{r}
M = is.na(X)
Ximpute  = X
for(j in 1:ncol(X)){
  Ximpute[M[,j],j] = mean(X[,j],na.rm=TRUE)
}
X
Ximpute
```
For a qualitative feature, the mode is a common choice
```{r}
Xqual = c('moo','cluck','cluck','oink',NA)
tbl   = table(Xqual)
(Xqual[is.na(Xqual)] = names(tbl)[which.max(tbl)])
```
Note that `mode' is a built-in function to R that checks the data structure:
```{r}
mode(Xqual)
```

# Iterative scheme
A common approach is to iteratively treat each feature as the supervisor and predict the missing values.

We need somehow to start this iteration.  A good omnibus solution to this
is to use mean/median/mode imputation for the 0th iteration.  Then, we
can iteratively update the missing values in each column of X with any supervised method.  We will use linear regression here.

0th iteration:
```{r}
M = is.na(X)
Ximpute = X
for(j in 1:ncol(X)){
  Ximpute[M[,j],j] = mean(X[,j],na.rm=TRUE)
}
```

Now we can start the iterations.  If computations are at a premium, we might only do a couple of iterations.  If we aren't so restricted, we might iterate until convergence

```{r}
maxIters  = 10
threshold = .01
converged = FALSE
nIters    = 0
while(!converged){
  nIters = nIters + 1
  Ximpute_old = Ximpute
  for(j in 1:ncol(X)){
    fitX_j = lm(Ximpute[,j]~Ximpute[,-j])
    Ximpute[M[,j],j] = fitX_j$fitted[M[,j]]
  }
  print(max(abs(Ximpute_old - Ximpute)/abs(Ximpute_old)))
  if( max(abs(Ximpute_old - Ximpute)/abs(Ximpute_old)) < threshold){
    converged = TRUE
  }
  if( nIters >= maxIters){
    converged  = TRUE
    warning('algorithm failed to converge')
  }
}
X
Ximpute
X_c
```

Let's looks at a linear model fit via ... 

## list-wise deletion:
```{r}
(summary(lm(Y~X)))
```
## iterative imputation
```{r}
(summary(lm(Y~Ximpute)))
```
## using the complete (but unknown) data
```{r}
(summary(lm(Y~X_c)))
```


# Another example
Let's look at using the iterative imputation scheme in two cases

* Features are independent
* Features are dependent

In both cases, we will examine an MAR missing data mechanism.  Let's define some functions first:

```{r iterativeFunction}
meanImputeF = function(X){
  Ximpute = X
  M       = is.na(X)
  for(j in 1:ncol(X)){
    Ximpute[M[,j],j] = mean(X[,j],na.rm=TRUE)
  }
  return(list('M' = M, 'Ximpute' = Ximpute))
}

iterativeF = function(X, maxIters = 10, threshold = 0.01, verbose = TRUE){
  meanImpute = meanImputeF(X)
  Ximpute    = meanImpute$Ximpute
  M          = meanImpute$M
  
  converged = FALSE
  nIters    = 0
  while(!converged){
    nIters = nIters + 1
    Ximpute_old = Ximpute
    for(j in 1:ncol(X)){
      fitX_j           = lm(Ximpute[,j]~Ximpute[,-j])
      Ximpute[M[,j],j] = fitX_j$fitted[M[,j]]
    }
    if(verbose){ print(max(abs(Ximpute_old - Ximpute)/abs(Ximpute_old))) }
    
    if( max(abs(Ximpute_old - Ximpute)/abs(Ximpute_old)) < threshold){
      converged = TRUE
    }
    if( nIters >= maxIters){
      break
      warning('algorithm failed to converge')
    }
  }
  return(Ximpute)
}
```

## Independent

```{r independent}
n           = 100
p           = 2

X_c          = matrix(rnorm(n*p),nrow=n)

X            = X_c
missing      = X_c[,1] > 1
X[missing,2] = NA

Xhat = iterativeF(X)
```

```{R}
ggplot(data = data.frame('x1_c' = X_c[,1],
                         'x2_c' = X_c[,2],
                         'missing' = missing)) + 
  geom_point(mapping = aes(x = x1_c, y = x2_c, color = missing), alpha = .25) + 
  geom_point(mapping = aes(x = x1, y = x2, color = missing),
             data = data.frame('x1' = Xhat[,1],
                         'x2' = Xhat[,2],
                         'missing' = missing)) 
  
```
## Dependent

Let's add some dependency to the data set

```{r dependent}
set.seed(1)
n           = 100
p           = 2

rho         = 0.9
Sigma       = matrix(rho,nrow=p,ncol=p)
diag(Sigma) = 1

X_c          = matrix(rnorm(n*p),nrow=n) %*% chol(Sigma)

X            = X_c
missing      = X_c[,1] > 1
X[missing,2] = NA

Xhat = iterativeF(X)
```

```{R}
ggplot(data = data.frame('x1_c' = X_c[,1],
                         'x2_c' = X_c[,2],
                         'missing' = missing)) + 
  geom_point(mapping = aes(x = x1_c, y = x2_c, color = missing), alpha = .25) + 
  geom_point(mapping = aes(x = x1, y = x2, color = missing),
             data = data.frame('x1' = Xhat[,1],
                         'x2' = Xhat[,2],
                         'missing' = missing)) 
  
```
